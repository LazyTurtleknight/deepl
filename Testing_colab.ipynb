{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LazyTurtleknight/deepl/blob/main/Testing_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip this cell if you are not working with colab\n",
        "\n",
        "!pip install opendatasets\n",
        "!pip install pandas\n",
        "!pip install albumentations\n"
      ],
      "metadata": {
        "id": "kXB77TGXznr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import albumentations as alb\n",
        "import cv2\n",
        "import tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import torch\n",
        "\n",
        "from torchsummary import summary\n",
        "from torch import nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "9wA2nYwf0GiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset from kaggle\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/balraj98/deepglobe-land-cover-classification-dataset\")"
      ],
      "metadata": {
        "id": "PmTqNahwpvGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRH03Q1AyFAc"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "\n",
        "# directories\n",
        "data_dir = 'deepglobe-land-cover-classification-dataset' # change to directory containing the data\n",
        "train_dir = 'train'\n",
        "log_dir = 'runs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsZRL97JyFAc"
      },
      "outputs": [],
      "source": [
        "# Load metadata and get random sample\n",
        "metadata = pd.read_csv(os.path.join(data_dir, 'metadata.csv'))\n",
        "\n",
        "sample = metadata[metadata['split'] == 'train'].sample(n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy6UiPb2yFAc"
      },
      "outputs": [],
      "source": [
        "# Plot random sample\n",
        "\n",
        "def plot(sample):\n",
        "\n",
        "  plt.figure(figsize=(5,4))\n",
        "  ax = plt.subplot(2,2,1)\n",
        "  plt.imshow(np.asarray(Image.open(os.path.join(data_dir, sample['sat_image_path'].iloc[0]))))\n",
        "  plt.gray()\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "\n",
        "  ax = plt.subplot(2,2,2)\n",
        "  plt.imshow(np.asarray(Image.open(os.path.join(data_dir, sample['mask_path'].iloc[0]))))\n",
        "  plt.gray()\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot(sample)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test albumentations\n",
        "\n",
        "sample_path = os.path.join(data_dir, sample['sat_image_path'].iloc[0])\n",
        "sample_mask_path = os.path.join(data_dir, sample['mask_path'].iloc[0])\n",
        "\n",
        "# Define augmentation pipeline\n",
        "transform = alb.Compose([\n",
        "    alb.RandomCrop(width=128, height=128),\n",
        "    alb.HorizontalFlip(p=0.5),\n",
        "    alb.RandomBrightnessContrast(p=0.2),],\n",
        "    # we want the mask and the image to have the same augmentation (or at least the same crop)\n",
        "    # this way we pass the image and the mask simultaneously to the pipeline\n",
        "    additional_targets={'image': 'image', 'mask': 'mask'}\n",
        "    )\n",
        "\n",
        "# Read an image with OpenCV and convert it to the RGB colorspace\n",
        "image = cv2.imread(sample_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "image_mask = cv2.imread(sample_mask_path)\n",
        "image_mask = cv2.cvtColor(image_mask, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Augment an image\n",
        "transformed = transform(image = image, mask = image_mask)\n",
        "transformed_image = transformed['image']\n",
        "transformed_image_mask = transformed['mask']"
      ],
      "metadata": {
        "id": "KsMmn_BHExMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(121),plt.imshow(transformed_image),plt.title('Image');\n",
        "plt.subplot(122),plt.imshow(transformed_image_mask),plt.title('Mask');"
      ],
      "metadata": {
        "id": "w5OKBXykGuma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# U-Net\n",
        "\n",
        "# One block of the encoder. Performs two convolutions and max pooling.\n",
        "class ConvPool(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.max = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c = self.conv2(self.conv1(x))\n",
        "        p = self.max(c)\n",
        "        return c, p\n",
        "\n",
        "# One block of the decoder. Performs upsampling and two convolutions.\n",
        "class UpConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
        "        super().__init__()\n",
        "        self.upsampling = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        u = self.upsampling(x)\n",
        "        #print(x.shape, u.shape, skip.shape)\n",
        "        u = torch.cat([u, skip], 0)\n",
        "        c = self.conv2(self.conv1(u))\n",
        "        return c, u\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, min, max):\n",
        "        super().__init__()\n",
        "        self.enc_layers = []\n",
        "        self.dec_layers = []\n",
        "        self.enc_final1 = None\n",
        "        self.enc_final2 = None\n",
        "        self.dec_final = None\n",
        "\n",
        "        # List of powers of 2 [16, 32, ..., max]\n",
        "        channels = []\n",
        "        power = min\n",
        "        for i in range(int(np.log2(max // min))):\n",
        "            channels.append(power)\n",
        "            power = power*2\n",
        "\n",
        "        self.enc_layers.append(ConvPool(in_channels, min))\n",
        "        for i in range(len(channels)-1):\n",
        "            enc_layer = ConvPool(channels[i], channels[i+1])\n",
        "            self.enc_layers.append(enc_layer)\n",
        "\n",
        "\n",
        "        for i in range(len(channels)-1):\n",
        "            dec_layer = UpConv(channels[i+1], channels[i])\n",
        "            self.dec_layers.insert(0, dec_layer)\n",
        "        self.dec_layers.insert(0, UpConv(max, channels[-1]))\n",
        "\n",
        "        self.enc_layers = nn.ModuleList(self.enc_layers)\n",
        "\n",
        "        self.dec_layers = nn.ModuleList(self.dec_layers)\n",
        "\n",
        "        self.enc_final1 = nn.Conv2d(channels[len(channels)-1], max, 3, 1, 'same')\n",
        "        self.enc_final2 = nn.Conv2d(max, max, 3, 1, 'same')\n",
        "        self.dec_final = nn.Conv2d(min, 1, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "        p = x\n",
        "        # Encoder\n",
        "        for layer in self.enc_layers:\n",
        "            c, p = layer(p)\n",
        "            skip_connections.append(c)\n",
        "\n",
        "        # Bottleneck\n",
        "        c =  self.enc_final2(self.enc_final1(p))\n",
        "\n",
        "        # Decoder\n",
        "        for layer in self.dec_layers:\n",
        "            skip = skip_connections.pop()\n",
        "            c, u = layer(c, skip) # if we do not need c we can use _ instead\n",
        "            print(f'After layer: {c.shape} {u.shape}')\n",
        "\n",
        "        return self.dec_final(c)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EOauTGYwq-Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up summary writer for tensorboard\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "writer = SummaryWriter(os.path.join(log_dir, current_time))\n"
      ],
      "metadata": {
        "id": "OKK0_N6pmXba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "# configure hyperparameters\n",
        "epochs = 50\n",
        "\n",
        "# init data loader/generator\n",
        "dataloader = None\n",
        "\n",
        "# init model, optimizer\n",
        "model = UNet(3, 16, 256)\n",
        "#print(model)\n",
        "opt = None\n",
        "loss_func = None\n",
        "\n",
        "sample = torch.tensor(transformed_image, dtype=torch.float).T # shape = (3, 256, 256)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "pred = model(sample)\n",
        "\n",
        "print(pred.shape)\n",
        "\n",
        "pred = pred.T.detach().numpy()\n",
        "\n",
        "plt.subplot(121),plt.imshow(pred),plt.title('Image');\n",
        "plt.subplot(122),plt.imshow(transformed_image_mask),plt.title('Mask');\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "\n",
        "\n",
        "#     for x, y in dataloader:\n",
        "#         pred = model(x)\n",
        "#         loss = loss_func(pred, y)\n",
        "\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "#         opt.zero_grad()\n"
      ],
      "metadata": {
        "id": "CGs0fakYloJp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}