{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LazyTurtleknight/deepl/blob/accelerate_performance/Training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas\n",
        "!pip install albumentations\n",
        "!pip install torchmetrics\n",
        "!pip install tensorboard"
      ],
      "metadata": {
        "id": "gunIv2fmvQ32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9wA2nYwf0GiM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import albumentations as alb\n",
        "#import tensorflow as tf\n",
        "import datetime\n",
        "import torch\n",
        "import numpy as np\n",
        "import opendatasets as od\n",
        "import tensorboard\n",
        "\n",
        "#from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from torchmetrics.classification import Dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8bZhJ17ESuj"
      },
      "outputs": [],
      "source": [
        "# Download dataset from kaggle\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/balraj98/deepglobe-land-cover-classification-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kLXZPYooESuj"
      },
      "outputs": [],
      "source": [
        "# model.py\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "# U-Net\n",
        "\n",
        "# Two convolution block. Performs two consecutive convolutions\n",
        "class TwoConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.module_list = nn.ModuleList([])\n",
        "\n",
        "        #Using Henriks convultion layering or the one introduced in the Unet paper?\n",
        "        self.module_list.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding))\n",
        "        self.module_list.append(nn.ReLU())\n",
        "\n",
        "        self.module_list.append(nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding))\n",
        "        self.module_list.append(nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x\n",
        "        for module in self.module_list:\n",
        "            y = module(y)\n",
        "        return y\n",
        "\n",
        "# UNet encoder block. Performs two convolutions and max pooling.\n",
        "class ConvPool(TwoConv):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
        "        super().__init__(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.max = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c = super().forward(x)\n",
        "        p = self.max(c)\n",
        "        return c, p\n",
        "\n",
        "# UNet decoder block. Performs upsampling, concatenation of the two inputs and two convolutions.\n",
        "class UpConv(TwoConv):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
        "        super().__init__(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        # We may use different upsampling method here.\n",
        "        self.upsampling = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        u = self.upsampling(x)\n",
        "        u = torch.cat([u, skip], 1)\n",
        "        c = super().forward(u)\n",
        "        return c, u\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, min, max, num_classes):\n",
        "        super().__init__()\n",
        "        self.enc_layers = nn.ModuleList([])\n",
        "        self.dec_layers = nn.ModuleList([])\n",
        "        self.enc_final = None\n",
        "        self.dec_final = None\n",
        "        self.softmax = None\n",
        "\n",
        "        # When go down the encoder/up the decoder the number of filter doubles/halves\n",
        "        # respectively. For that we will generate the powers of two.\n",
        "        # List of powers of 2 [min, 2*min, 4*min, ..., max]\n",
        "        channels = []\n",
        "        power = min\n",
        "        for i in range(int(np.log2(max // min))):\n",
        "            channels.append(power)\n",
        "            power = power*2\n",
        "\n",
        "        # Construct list of blocks for the encoder\n",
        "        self.enc_layers.append(ConvPool(in_channels, min))\n",
        "        for i in range(len(channels)-1):\n",
        "            enc_layer = ConvPool(channels[i], channels[i+1])\n",
        "            self.enc_layers.append(enc_layer)\n",
        "\n",
        "        # Construct list of blocks for the encoder\n",
        "        for i in range(len(channels)-1):\n",
        "            dec_layer = UpConv(channels[i+1], channels[i])\n",
        "            self.dec_layers.insert(0, dec_layer)\n",
        "        self.dec_layers.insert(0, UpConv(max, channels[-1]))\n",
        "\n",
        "        # Set up final convolutions for the encoder and decoder\n",
        "        self.enc_final = TwoConv(channels[len(channels)-1], max, 3, 1, 'same')\n",
        "        self.dec_final = nn.Conv2d(min, num_classes, 1, 1)\n",
        "        self.softmax = nn.Softmax(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Collect the values for skip connections to the decoder\n",
        "        skip_connections = []\n",
        "        p = x\n",
        "        # Encoder\n",
        "        for layer in self.enc_layers:\n",
        "            c, p = layer(p)\n",
        "            skip_connections.append(c)\n",
        "\n",
        "        # Bottleneck\n",
        "        c =  self.enc_final(p)\n",
        "\n",
        "        # Decoder\n",
        "        for layer in self.dec_layers:\n",
        "            skip = skip_connections.pop()\n",
        "            c, u = layer(c, skip) # if we do not need c we can use _ instead\n",
        "        c = self.dec_final(c)\n",
        "\n",
        "        return self.softmax(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5ITJlGz0ESuk"
      },
      "outputs": [],
      "source": [
        "# dataset.py\n",
        "#Custom dataset for SatelliteSet\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# Custom dataset class to load deep globe dataset\n",
        "class SatelliteSet(Dataset):\n",
        "    def __init__(self,\n",
        "                 # mpandas dataframe loaded with a meta data csv containing image file names\n",
        "                 meta_data,\n",
        "                 # Class dictionary\n",
        "                 class_dict,\n",
        "                 # directory where the data is stored\n",
        "                 data_dir,\n",
        "                 # albumentations transform\n",
        "                 transform=None):\n",
        "        self.meta_data = meta_data\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.class_dict = class_dict\n",
        "\n",
        "        \"\"\"\n",
        "         Note:\n",
        "                - We load data completely into main memory and into gpu memory (half of the samples are on cuda, the other on main)\n",
        "                - samples are cropped -> no random crop each epoch\n",
        "                - idx_to_divice keeps track of where samples are (cuda or cpu)\n",
        "        \"\"\"\n",
        "        self.idx_to_device = dict()\n",
        "        # shape: (len(self) // 2) x 3 x 256 x 256\n",
        "        self.images_cpu = None\n",
        "        # shape: (len(self) // 2) x 7 x 256 x 256\n",
        "        self.images_cuda = None\n",
        "        # shape: (len(self) // 2) x 3 x 256 x 256\n",
        "        self.masks_cpu = None\n",
        "        # shape: (len(self) // 2) x 7 x 256 x 256\n",
        "        self.masks_cuda = None\n",
        "        self.prefetch()\n",
        "\n",
        "\n",
        "    def print_memory(self):\n",
        "        func = lambda t: print(t.element_size() * t.nelement())\n",
        "        func(self.images_cpu)\n",
        "        func(self.images_cuda)\n",
        "        func(self.masks_cpu)\n",
        "        func(self.masks_cuda)\n",
        "\n",
        "    # number of samples in dataset\n",
        "    def __len__(self):\n",
        "        return len(self.meta_data)\n",
        "\n",
        "    def prefetch(self):\n",
        "        toggle = True\n",
        "        for idx in range(len(self) // 2):\n",
        "            # Load sample\n",
        "            image, mask = self.load_sample(idx)\n",
        "            #if self.transform:\n",
        "            #    image, mask = self.transform(image, mask)\n",
        "            image, mask = torch.from_numpy(image), torch.from_numpy(mask)\n",
        "            if toggle:\n",
        "                if self.images_cpu == None:\n",
        "                    self.images_cpu = image.unsqueeze(0).cpu()\n",
        "                    self.masks_cpu = mask.unsqueeze(0).cpu()\n",
        "                else:\n",
        "                    self.images_cpu = torch.cat((self.images_cpu, image.unsqueeze(0).cpu()), dim=0)\n",
        "                    self.masks_cpu = torch.cat((self.masks_cpu, mask.unsqueeze(0).cpu()), dim=0)\n",
        "                self.idx_to_device[idx] = ('cpu', self.images_cpu.shape[0]-1)\n",
        "            else:\n",
        "                if self.images_cuda == None:\n",
        "                    self.images_cuda = image.unsqueeze(0).cuda()\n",
        "                    self.masks_cuda = mask.unsqueeze(0).cuda()\n",
        "                else:\n",
        "                    self.images_cuda = torch.cat((self.images_cuda, image.unsqueeze(0).cuda()), dim=0)\n",
        "                    self.masks_cuda = torch.cat((self.masks_cuda, mask.unsqueeze(0).cuda()), dim=0)\n",
        "                self.idx_to_device[idx] = ('cuda', self.images_cuda.shape[0]-1)\n",
        "            toggle = not toggle\n",
        "            if idx % 50 == 1:\n",
        "                print(f\"cpu = {self.images_cuda.shape[0]} and cuda = {self.images_cpu.shape[0]}\")\n",
        "                self.print_memory()\n",
        "\n",
        "    def transform(self, image, mask):\n",
        "        # In the transform from albumentation we pass both the image and the mask together to make sure\n",
        "        # they undergo the same transformation, e.g. this ensure both have the same random crop\n",
        "        transformed = self.transform(image = image, mask = mask)\n",
        "        image = transformed['image'].to(torch.float32)\n",
        "        mask = transformed['mask']\n",
        "        # Mask will be a one hot encoded matrix with dimensions 7 x 256 x 256\n",
        "        # First dimenion corresponds to class label\n",
        "        mask = np.apply_along_axis(lambda k: self.class_dict[tuple(k)], 2, mask)\n",
        "        mask = (mask[..., None] == np.arange(7)).astype(mask.dtype)\n",
        "        mask = np.transpose(mask, (2, 0, 1))\n",
        "        mask = torch.tensor(mask).to(torch.float32)\n",
        "        return image, mask\n",
        "\n",
        "    def load_sample(self, idx):\n",
        "            # Read image\n",
        "            img_path = os.path.join(self.data_dir, self.meta_data.iloc[idx]['sat_image_path'])\n",
        "            image = cv2.imread(img_path)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            # Read target mask\n",
        "            mask_path = os.path.join(self.data_dir, self.meta_data.iloc[idx]['mask_path'])\n",
        "            mask = cv2.imread(mask_path)\n",
        "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            return image, mask\n",
        "    def __getitem__(self, idx):\n",
        "        image, mask = 0, 0\n",
        "        if idx not in self.idx_to_device():\n",
        "            image, mask = self.load_sample(idx)\n",
        "            image, mask = torch.from_numpy(image).cuda(), torch.from_numpy(mask).cuda()\n",
        "        else:\n",
        "            device, index = self.idx_to_device[idx]\n",
        "            if device == 'cuda':\n",
        "                image, mask = self.images_cuda[index], self.masks_cuda[index]\n",
        "            else:\n",
        "                image, mask = self.images_cpu[index].cuda(), self.masks_cpu[index].cuda()\n",
        "        image, mask = self.transform(image), self.transform(mask)\n",
        "        return image, mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_P8xHWCpESuk"
      },
      "outputs": [],
      "source": [
        "# utils.py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from torchmetrics import JaccardIndex\n",
        "from torchmetrics.classification import Dice\n",
        "\n",
        "def plot(sample, data_dir):\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    ax = plt.subplot(2,2,1)\n",
        "    plt.imshow(np.asarray(Image.open(os.path.join(data_dir, sample['sat_image_path'].iloc[0]))))\n",
        "    plt.gray()\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "\n",
        "    ax = plt.subplot(2,2,2)\n",
        "    plt.imshow(np.asarray(Image.open(os.path.join(data_dir, sample['mask_path'].iloc[0]))))\n",
        "    plt.gray()\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# TODO: make something like a dictionary for parametere to pass to data loader\n",
        "def get_data_loaders(data_dir, transform, shuffle_dataset, test_split, random_seed, batch_size):\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    # Load metadata csv\n",
        "    metadata = pd.read_csv(os.path.join(data_dir, 'metadata.csv'))\n",
        "\n",
        "    # We need to filter for row where 'split' is 'train' because samples where\n",
        "    # 'split' is 'valid' or 'test' have no target mask\n",
        "    metadata = metadata[metadata['split'] == 'train']\n",
        "\n",
        "    class_dict = pd.read_csv(os.path.join(data_dir, 'class_dict.csv'))\n",
        "\n",
        "    classes = {}\n",
        "    c = 0\n",
        "    for i in class_dict.index:\n",
        "        classes[tuple(class_dict.iloc[i,1:])] = c\n",
        "        c += 1\n",
        "\n",
        "    # We need to filter for row where 'split' is 'train' because samples where\n",
        "    # 'split' is 'valid' or 'test' have no target mask\n",
        "\n",
        "    dataset = SatelliteSet(meta_data=metadata, class_dict=classes, data_dir=data_dir, transform=transform)\n",
        "\n",
        "    # Creating data indices for training and validation splits:\n",
        "    dataset_size = len(dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(test_split * dataset_size))\n",
        "    #TODO:Implement validation\n",
        "\n",
        "    if shuffle_dataset:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "    train_indices, test_indices = indices[split:], indices[:split]\n",
        "\n",
        "    # Creating PT data samplers and loaders:\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                            sampler=train_sampler)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                                sampler=test_sampler)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def evaluate(model, writer, dataloader, epoch, device):\n",
        "    iou_score = 0\n",
        "    iou = JaccardIndex('multiclass', num_classes=7).to(device)\n",
        "    dice_score = 0\n",
        "    dice = Dice(num_classes=7).to(device)\n",
        "    for x, y in dataloader:\n",
        "        pred = model(x)\n",
        "        pred = torch.argmax(pred, 1)\n",
        "        y = torch.argmax(y, 1)\n",
        "        # Calculate IOU\n",
        "        iou_score += iou(pred, y)\n",
        "        # Calculate DICE\n",
        "        dice_score += dice(pred, y)\n",
        "\n",
        "    writer.add_scalar('DICE Score', dice_score / len(dataloader), epoch)\n",
        "    writer.add_scalar('IOU Score', iou_score / len(dataloader), epoch)\n",
        "\n",
        "def get_iou_score(pred, y):\n",
        "    iou_score = 0\n",
        "    intersection = np.logical_and(y, pred)\n",
        "    union = np.logical_or(y, pred)\n",
        "    iou_score += np.sum(intersection) / np.sum(union)\n",
        "    return iou_score\n",
        "\n",
        "def get_dice_score(pred, y):\n",
        "    dice_score = 0\n",
        "    intersection = np.logical_and(y, pred)\n",
        "    dice_score += np.sum(intersection) / (y.size() + pred.size())\n",
        "    return dice_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pRH03Q1AyFAc"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "\n",
        "# directories\n",
        "data_dir = 'deepglobe-land-cover-classification-dataset' # change to directory containing the data\n",
        "trained_models = 'trained_models'\n",
        "train_dir = 'train'\n",
        "log_dir = 'runs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SuBN7hd2ESul"
      },
      "outputs": [],
      "source": [
        "# Training configuration (hyperparameters)\n",
        "\n",
        "## Data\n",
        "test_split = .2 #20% for test split\n",
        "#valdation_split = .2 #20% for validation split\n",
        "random_seed = np.random.seed()\n",
        "shuffle_dataset = True\n",
        "\n",
        "transform = alb.Compose([\n",
        "    alb.RandomCrop(width=256, height=256),\n",
        "    alb.HorizontalFlip(p=0.5),\n",
        "    ToTensorV2()\n",
        "    ],\n",
        "    # we want the mask and the image to have the same augmentation (especially when we crop)\n",
        "    # this way we pass the image and the mask simultaneously to the pipeline\n",
        "    additional_targets={'image': 'image', 'mask': 'mask'}\n",
        "    )\n",
        "\n",
        "## model architecture\n",
        "in_channels = 3\n",
        "min_channels = 16\n",
        "max_channels = 128\n",
        "num_classes = 7\n",
        "\n",
        "## Training\n",
        "learning_rate = 0.1\n",
        "batch_size = 20\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGs0fakYloJp"
      },
      "outputs": [],
      "source": [
        "from sys import breakpointhook\n",
        "# Training\n",
        "\n",
        "# setup training enviroment\n",
        "device = torch.device(\"cuda\")\n",
        "#Labels\n",
        "\n",
        "\n",
        "# init data loader/generator\n",
        "train_dataloader, test_dataloader = get_data_loaders(data_dir, transform, shuffle_dataset, test_split, random_seed, batch_size)\n",
        "\n",
        "# init model, optimizer and loss function\n",
        "model = UNet(in_channels, min_channels, max_channels, num_classes)\n",
        "model.to(device)\n",
        "opt = torch.optim.SGD(model.parameters(), learning_rate)\n",
        "loss_func = torch.nn.CrossEntropyLoss() #Dice(num_classes=num_classes)\n",
        "\n",
        "# Set up summary writer for tensorboard\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "writer = SummaryWriter(os.path.join(log_dir, current_time))\n",
        "\n",
        "# start training\n",
        "for epoch in range(1, epochs+1):\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "    c = 1\n",
        "    loss_avg = 0\n",
        "    for x, y in train_dataloader:\n",
        "        print(f\"Batch number {c} of {len(train_dataloader)}\")\n",
        "        opt.zero_grad()\n",
        "        pred = model(x)\n",
        "        # pred has shape batch_size x num_classes x width x height\n",
        "        # apply softmax to find what it thinks is the most likely class label\n",
        "        pred = torch.softmax(pred, 1)\n",
        "        # y has shape batch_size x num_classes x width x height\n",
        "        # the num_classes is a one hot encoding where the index corresponds to a class\n",
        "        # which can be looked up in the class_dict\n",
        "        loss = loss_func(pred, y)\n",
        "        loss_avg += loss\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        c += 1\n",
        "\n",
        "    writer.add_scalar('Loss', loss_avg, epoch)\n",
        "\n",
        "    # Evaluate model\n",
        "    model.eval()\n",
        "    evaluate(model, writer, test_dataloader, epoch, device)\n",
        "    model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8ltRRM3ESul"
      },
      "outputs": [],
      "source": [
        "# Launch tensorboard\n",
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir runs/20231205-151422"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1pRWV_VESul"
      },
      "outputs": [],
      "source": [
        "# List running tensorboard instances\n",
        "tensorboard.notebook.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWtgf1hzESum"
      },
      "outputs": [],
      "source": [
        "# kill process with id\n",
        "!kill -9 32287"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Uf_DDyHESum"
      },
      "outputs": [],
      "source": [
        "# Save model after training\n",
        "torch.save(model.state_dict(), os.path.join(trained_models, current_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOJqYFFZESum"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "\n",
        "model = UNet(0, 0, 0, 0)\n",
        "model.load_state_dict(torch.load(PATH_To_Saved_Model))\n",
        "model.eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}